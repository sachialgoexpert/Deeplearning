{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5516380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    FlaxAutoModelForSeq2SeqLM,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForDocumentQuestionAnswering,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoModelForMaskGeneration,\n",
    "    AutoModelForObjectDetection,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelForMultipleChoice,\n",
    "    AutoModelForNextSentencePrediction,\n",
    "    AutoModelForPreTraining,\n",
    "    AutoModelForTableQuestionAnswering,\n",
    "    AutoModelForTextEncoding,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoModelForSemanticSegmentation,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5d4f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a74d983",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10d1b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "973c6b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25000/25000 [00:01<00:00, 13002.73 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_ds=dataset.map(tokenizer_fn,batched=True)\n",
    "tokenized_ds=tokenized_ds.remove_columns(['text'])\n",
    "tokenized_ds=tokenized_ds.rename_column(\"label\",\"labels\")\n",
    "tokenized_ds.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0d008c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46279e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = torch.argmax(torch.tensor(logits), dim=1)\n",
    "    return accuracy.compute(predictions=preds, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2c83e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./imdb_bert\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fde125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9365/1023739189.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "519b827b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3126' max='3126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3126/3126 04:46, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.222900</td>\n",
       "      <td>0.202762</td>\n",
       "      <td>0.920440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>0.259592</td>\n",
       "      <td>0.924160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3126, training_loss=0.2077153043264925, metrics={'train_runtime': 285.3903, 'train_samples_per_second': 175.199, 'train_steps_per_second': 10.953, 'total_flos': 6577776384000000.0, 'train_loss': 0.2077153043264925, 'epoch': 2.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bf89b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.259591668844223,\n",
       " 'eval_accuracy': 0.92416,\n",
       " 'eval_runtime': 39.0234,\n",
       " 'eval_samples_per_second': 640.642,\n",
       " 'eval_steps_per_second': 40.053,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63b4194",
   "metadata": {},
   "source": [
    "### AutoTokenizer\n",
    "Loads the correct tokenizer for a pretrained model\n",
    "\n",
    "Converts raw text ‚Üí tokens ‚Üí input IDs\n",
    "Problems it supports\n",
    "\n",
    "* Required for all NLP tasks\n",
    "\n",
    "Handles:\n",
    "\n",
    "tokenization\n",
    "\n",
    "padding\n",
    "\n",
    "truncation\n",
    "\n",
    "attention masks\n",
    "\n",
    "üîπ Example use cases\n",
    "\n",
    "Sentiment analysis\n",
    "\n",
    "QA\n",
    "\n",
    "NER\n",
    "\n",
    "Text generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50256cf",
   "metadata": {},
   "source": [
    "### AutoModelForSequenceClassification\n",
    "- Model type\n",
    "\n",
    "    Encoder-based models (BERT, RoBERTa, DistilBERT)\n",
    "\n",
    "    Adds a classification head\n",
    "- Problems:\n",
    "\n",
    "    Sentiment analysis (IMDB, Amazon)\n",
    "\n",
    "    Topic classification (AG News, BBC)\n",
    "\n",
    "    Spam detection\n",
    "\n",
    "    Intent classification\n",
    "\n",
    "    Toxic comment detection\n",
    "-  Output\n",
    "\n",
    "    One label per sequence\n",
    "- Variants\n",
    "\n",
    "    bert-base-uncased\n",
    "\n",
    "    distilbert-base-uncased (faster)\n",
    "\n",
    "    roberta-base (better accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a71208",
   "metadata": {},
   "source": [
    "### AutoModelForMultipleChoiceüîπ Model type\n",
    "\n",
    "    Encoder models + multiple-choice head\n",
    "\n",
    "- Problems solved\n",
    "\n",
    "    Exam-style questions\n",
    "\n",
    "    Reading comprehension with options\n",
    "\n",
    "    SWAG, RACE datasets\n",
    "\n",
    "- Output\n",
    "\n",
    "    Probability for each choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7e056c",
   "metadata": {},
   "source": [
    "2. Token Classification (NER, POS)\n",
    "### AutoModelForTokenClassification\n",
    "\n",
    "- Problems\n",
    "\n",
    "    Named Entity Recognition (NER)\n",
    "\n",
    "    Part-of-Speech tagging\n",
    "\n",
    "    Slot filling\n",
    "\n",
    "- Datasets\n",
    "\n",
    "    CoNLL-2003\n",
    "\n",
    "    OntoNotes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd746e8d",
   "metadata": {},
   "source": [
    "üîπ 3. Question Answering\n",
    "### AutoModelForQuestionAnswering\n",
    "- Problems\n",
    "\n",
    "    Extract answer spans from text\n",
    "\n",
    "    Reading comprehension\n",
    "\n",
    "- Datasets\n",
    "\n",
    "    SQuAD\n",
    "\n",
    "    Natural Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71bf3be",
   "metadata": {},
   "source": [
    "4. Text Pair Classification\n",
    "### AutoModelForSequenceClassification\n",
    "- Problems\n",
    "\n",
    "    Sentence similarity\n",
    "\n",
    "    Paraphrase detection\n",
    "\n",
    "    Natural Language Inference (NLI)\n",
    "\n",
    "- Datasets\n",
    "\n",
    "    MRPC\n",
    "\n",
    "    SNLI\n",
    "\n",
    "    MNLI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9476239f",
   "metadata": {},
   "source": [
    "5. Zero-Shot Classification\n",
    "### pipeline(\"zero-shot-classification\")\n",
    "- Problems\n",
    "\n",
    "    Topic classification without training\n",
    "\n",
    "    Intent detection on new labels\n",
    "\n",
    "- Uses:\n",
    "\n",
    "    facebook/bart-large-mnli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a48d30c",
   "metadata": {},
   "source": [
    "6. Masked Language Modeling (Pretraining / Adaptation)\n",
    "###  AutoModelForMaskedLM\n",
    "\n",
    "- Problems\n",
    "\n",
    "    Domain adaptation\n",
    "\n",
    "    Vocabulary learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc9e536",
   "metadata": {},
   "source": [
    "7. Text Generation (Not BERT, but AutoModels)\n",
    "### AutoModelForCausalLM\n",
    "\n",
    "- Models\n",
    "\n",
    "    GPT-2\n",
    "\n",
    "    LLaMA\n",
    "\n",
    "    Falcon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f947616",
   "metadata": {},
   "source": [
    "### AutoModelForTableQuestionAnswering\n",
    "üîπ Model type\n",
    "\n",
    "Table-aware transformers (TAPAS)\n",
    "\n",
    "üîπ Problems solved\n",
    "\n",
    "QA over structured tables\n",
    "\n",
    "    Spreadsheets\n",
    "\n",
    "    CSV-style data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd62b5f",
   "metadata": {},
   "source": [
    "### AutoModelForMaskedLM\n",
    "\n",
    "- Model type\n",
    "\n",
    "Encoder models (BERT)\n",
    "\n",
    "- Problems solved\n",
    "\n",
    "Masked word prediction\n",
    "\n",
    "Pretraining\n",
    "\n",
    "Domain adaptation\n",
    "\n",
    "- Example\n",
    "\n",
    "‚ÄúThe movie was [MASK].‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73405975",
   "metadata": {},
   "source": [
    "### AutoModelForCausalLM\n",
    "- Model type\n",
    "\n",
    "    Decoder-only models (GPT, LLaMA)\n",
    "\n",
    "- Problems solved\n",
    "\n",
    "    Text generation\n",
    "\n",
    "    Chatbots\n",
    "\n",
    "    Code generation\n",
    "\n",
    "    Story writing\n",
    "\n",
    "- Generation style\n",
    "\n",
    "    Left-to-right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a46be",
   "metadata": {},
   "source": [
    "AutoModelForSeq2SeqLM\n",
    "- Model type\n",
    "\n",
    "    Encoder‚ÄìDecoder (T5, BART)\n",
    "\n",
    "- Problems solved\n",
    "\n",
    "    Translation\n",
    "\n",
    "    Summarization\n",
    "\n",
    "    Paraphrasing\n",
    "\n",
    "    Question generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a3eebf",
   "metadata": {},
   "source": [
    "# TAsk Specific Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc7fb7f",
   "metadata": {},
   "source": [
    "Sentiment Analysis / Text Classification\n",
    "üìå Datasets\n",
    "\n",
    "IMDB\n",
    "\n",
    "Amazon Reviews\n",
    "\n",
    "Yelp Reviews\n",
    "\n",
    "AG News\n",
    "\n",
    "BBC News\n",
    "\n",
    "TweetEval\n",
    "\n",
    "‚úÖ AutoModel\n",
    "AutoModelForSequenceClassification\n",
    "- explanation: \n",
    "\n",
    "‚ÄúThis is used when the entire input text maps to a single label, such as sentiment, topic, or intent. The model outputs logits for each class.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436bb6af",
   "metadata": {},
   "source": [
    "2Ô∏è‚É£ Named Entity Recognition (NER) / POS\n",
    "üìå Datasets\n",
    "\n",
    "CoNLL-2003\n",
    "\n",
    "OntoNotes\n",
    "\n",
    "WikiANN\n",
    "\n",
    "‚úÖ AutoModel\n",
    "AutoModelForTokenClassification\n",
    "\n",
    "üé§ Interview-ready explanation\n",
    "\n",
    "‚ÄúThis model performs token-level classification, meaning it predicts a label for each token, which is ideal for NER, POS tagging, and slot filling.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a60ac92",
   "metadata": {},
   "source": [
    "3Ô∏è‚É£ Question Answering (Extractive)\n",
    "üìå Datasets\n",
    "\n",
    "SQuAD\n",
    "\n",
    "Natural Questions\n",
    "\n",
    "TriviaQA\n",
    "\n",
    "‚úÖ AutoModel\n",
    "AutoModelForQuestionAnswering\n",
    "\n",
    "üé§ Interview-ready explanation\n",
    "\n",
    "‚ÄúThis model predicts start and end token positions in the context, allowing it to extract an answer span for a given question.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9178c8fc",
   "metadata": {},
   "source": [
    "4Ô∏è‚É£ Document Question Answering (Invoices, PDFs)\n",
    "üìå Datasets\n",
    "\n",
    "DocVQA\n",
    "\n",
    "RVL-CDIP\n",
    "\n",
    "FUNSD\n",
    "\n",
    "‚úÖ AutoModel\n",
    "AutoModelForDocumentQuestionAnswering\n",
    "\n",
    "üé§ Interview-ready explanation\n",
    "\n",
    "‚ÄúThis model combines text and layout information to answer questions over structured documents like invoices and forms.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f37aa6",
   "metadata": {},
   "source": [
    "5Ô∏è‚É£ Table Question Answering\n",
    "üìå Datasets\n",
    "\n",
    "WikiTableQuestions\n",
    "\n",
    "SQA\n",
    "\n",
    "‚úÖ AutoModel\n",
    "AutoModelForTableQuestionAnswering\n",
    "\n",
    "üé§ Interview-ready explanation\n",
    "\n",
    "‚ÄúThis model understands tabular data and answers questions by reasoning over rows and columns instead of free text.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc43074f",
   "metadata": {},
   "source": [
    "6Ô∏è‚É£ Text Generation / Chatbots\n",
    "üìå Datasets\n",
    "\n",
    "OpenWebText\n",
    "\n",
    "WikiText\n",
    "\n",
    "Custom conversational data\n",
    "\n",
    "‚úÖ AutoModel\n",
    "AutoModelForCausalLM\n",
    "\n",
    "üé§ Interview-ready explanation\n",
    "\n",
    "‚ÄúThis model generates text autoregressively, predicting the next token based on previous tokens, which is ideal for chatbots and text generation.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdcdc06",
   "metadata": {},
   "source": [
    "Translation / Summarization / Paraphrasing\n",
    "üìå Datasets\n",
    "\n",
    "WMT (translation)\n",
    "\n",
    "CNN/DailyMail (summarization)\n",
    "\n",
    "XSum\n",
    "\n",
    "‚úÖ AutoModel\n",
    "AutoModelForSeq2SeqLM\n",
    "\n",
    "üé§ Interview-ready explanation\n",
    "\n",
    "‚ÄúThis encoder‚Äìdecoder model transforms one sequence into another, making it suitable for translation, summarization, and text rewriting.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a3b7d",
   "metadata": {},
   "source": [
    "8Ô∏è‚É£ Masked Language Modeling (Pretraining)\n",
    "üìå Datasets\n",
    "\n",
    "Wikipedia\n",
    "\n",
    "BookCorpus\n",
    "\n",
    "Domain-specific corpora\n",
    "\n",
    "‚úÖ AutoModel\n",
    "AutoModelForMaskedLM\n",
    "\n",
    "üé§ Interview-ready explanation\n",
    "\n",
    "‚ÄúThis model predicts masked tokens in a sentence and is primarily used for pretraining or domain adaptation.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f2aeed",
   "metadata": {},
   "source": [
    "9Ô∏è‚É£ Sentence Embeddings / Semantic Search\n",
    "üìå Datasets\n",
    "\n",
    "STS-B\n",
    "\n",
    "MS MARCO\n",
    "\n",
    "Custom similarity data\n",
    "\n",
    "‚úÖ AutoModel\n",
    "AutoModelForTextEncoding\n",
    "\n",
    "üé§ Interview-ready explanation\n",
    "\n",
    "‚ÄúThis model converts text into dense vector embeddings used for semantic similarity, clustering, and retrieval tasks.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d775a00",
   "metadata": {},
   "source": [
    "üîü Multiple Choice QA\n",
    "üìå Datasets\n",
    "\n",
    "SWAG\n",
    "\n",
    "RACE\n",
    "\n",
    "CommonsenseQA\n",
    "\n",
    "‚úÖ AutoModel\n",
    "AutoModelForMultipleChoice\n",
    "\n",
    "üé§ Interview-ready explanation\n",
    "\n",
    "‚ÄúThis model scores multiple candidate answers and selects the most likely one, commonly used in exam-style QA tasks.‚Äù\n",
    "\n",
    "1Ô∏è‚É£1Ô∏è‚É£ Vision Tasks (Non-NLP, but good to know)\n",
    "üìå Object Detection\n",
    "\n",
    "COCO ‚Üí AutoModelForObjectDetection\n",
    "\n",
    "üìå Semantic Segmentation\n",
    "\n",
    "Cityscapes ‚Üí AutoModelForSemanticSegmentation\n",
    "\n",
    "üé§ Interview-ready explanation\n",
    "\n",
    "‚ÄúThese models extend transformers to vision tasks such as object detection and pixel-level segmentation.‚Äù"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
